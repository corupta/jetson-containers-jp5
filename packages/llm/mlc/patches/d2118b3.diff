diff --git a/3rdparty/tvm b/3rdparty/tvm
--- a/3rdparty/tvm
+++ b/3rdparty/tvm
@@ -1 +1 @@
-Subproject commit 9c894f78fdef156263ced19eed67e79203ca4a11
+Subproject commit 9c894f78fdef156263ced19eed67e79203ca4a11-dirty
diff --git a/CMakeLists.txt b/CMakeLists.txt
index a010a051..68476415 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -47,13 +47,13 @@ set(CMAKE_POSITION_INDEPENDENT_CODE ON)
 # tvm runtime config: minimize runtime components
 set(USE_RPC OFF)
 set(USE_MICRO OFF)
-set(USE_GRAPH_EXECUTOR OFF)
+#set(USE_GRAPH_EXECUTOR OFF)
 set(USE_GRAPH_EXECUTOR_DEBUG OFF)
 set(USE_AOT_EXECUTOR OFF)
 set(USE_PROFILER OFF)
 set(USE_GTEST OFF)
 set(USE_LIBBACKTRACE OFF)
-set(BUILD_DUMMY_LIBTVM ON)
+#set(BUILD_DUMMY_LIBTVM ON)
 if(NOT DEFINED TVM_SOURCE_DIR)
   if(DEFINED ENV{TVM_SOURCE_DIR})
     set(TVM_SOURCE_DIR "$ENV{TVM_SOURCE_DIR}")
diff --git a/python/mlc_llm/libinfo.py b/python/mlc_llm/libinfo.py
index 2212d8c7..a322ef68 100644
--- a/python/mlc_llm/libinfo.py
+++ b/python/mlc_llm/libinfo.py
@@ -4,7 +4,7 @@
 import os
 import sys
 
-__version__ = "0.1.dev0"
+__version__ = "0.20.0"
 MLC_LIBRARY_PATH = os.environ.get("MLC_LIBRARY_PATH", None)
 
 
diff --git a/python/mlc_llm/quantization/ft_quantization.py b/python/mlc_llm/quantization/ft_quantization.py
index 4a158460..7cd8fc6a 100644
--- a/python/mlc_llm/quantization/ft_quantization.py
+++ b/python/mlc_llm/quantization/ft_quantization.py
@@ -207,7 +207,7 @@ class FTQuantize:  # pylint: disable=too-many-instance-attributes
                                 relax.call_pure_packed(
                                     "cutlass.ft_preprocess_weight",
                                     lv1,
-                                    detect_cuda_arch_list(target=target)[0],
+                                    int(detect_cuda_arch_list(target=target)[0]),
                                     DataType(self.quantize_dtype).bits == 4,
                                     sinfo_args=lv1.struct_info,
                                 )
diff --git a/python/mlc_llm/quantization/quantization.py b/python/mlc_llm/quantization/quantization.py
index 8afa3bf0..b16fd544 100644
--- a/python/mlc_llm/quantization/quantization.py
+++ b/python/mlc_llm/quantization/quantization.py
@@ -77,6 +77,17 @@ QUANTIZATION: Dict[str, Quantization] = {
         quantize_embedding=True,
         quantize_final_fc=True,
     ),
+    "q8f16_0": GroupQuantize(
+        name="q8f16_0",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="float16",
+        linear_weight_layout="KN",
+        quantize_embedding=True,
+        quantize_final_fc=True,
+    ),
     "q4f16_1": GroupQuantize(
         name="q4f16_1",
         kind="group-quant",
@@ -88,6 +99,17 @@ QUANTIZATION: Dict[str, Quantization] = {
         quantize_embedding=True,
         quantize_final_fc=True,
     ),
+    "q8f16_1": GroupQuantize(
+        name="q8f16_1",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="float16",
+        linear_weight_layout="NK",
+        quantize_embedding=True,
+        quantize_final_fc=True,
+    ),
     "q4bf16_0": GroupQuantize(
         name="q4bf16_0",
         kind="group-quant",
@@ -99,6 +121,17 @@ QUANTIZATION: Dict[str, Quantization] = {
         quantize_embedding=True,
         quantize_final_fc=True,
     ),
+    "q8bf16_0": GroupQuantize(
+        name="q8bf16_0",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="bfloat16",
+        linear_weight_layout="KN",
+        quantize_embedding=True,
+        quantize_final_fc=True,
+    ),
     "q4bf16_1": GroupQuantize(
         name="q4bf16_1",
         kind="group-quant",
@@ -110,6 +143,28 @@ QUANTIZATION: Dict[str, Quantization] = {
         quantize_embedding=True,
         quantize_final_fc=True,
     ),
+    "q8bf16_1": GroupQuantize(
+        name="q8bf16_1",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="bfloat16",
+        linear_weight_layout="NK",
+        quantize_embedding=True,
+        quantize_final_fc=True,
+    ),
+    "q8bf16_2": GroupQuantize(
+        name="q8bf16_1",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="bfloat16",
+        linear_weight_layout="NK",
+        quantize_embedding=False,
+        quantize_final_fc=False,
+    ),
     "q4f32_1": GroupQuantize(
         name="q4f32_1",
         kind="group-quant",
@@ -132,6 +187,17 @@ QUANTIZATION: Dict[str, Quantization] = {
         quantize_embedding=False,
         quantize_final_fc=False,
     ),
+    "q8f16_2": GroupQuantize(
+        name="q8f16_2",
+        kind="group-quant",
+        group_size=32,
+        quantize_dtype="int8",
+        storage_dtype="uint32",
+        model_dtype="float16",
+        linear_weight_layout="NK",
+        quantize_embedding=False,
+        quantize_final_fc=False,
+    ),
     "q4f16_autoawq": AWQQuantize(
         name="q4f16_autoawq",
         kind="awq",
diff --git a/python/setup.py b/python/setup.py
index 0eb7a3a7..b964530e 100644
--- a/python/setup.py
+++ b/python/setup.py
@@ -47,7 +47,7 @@ def git_describe_version(original_version):
 
 
 LIB_LIST, __version__ = get_lib_path()
-__version__ = git_describe_version(__version__)
+#__version__ = git_describe_version(__version__)
 
 
 class BinaryDistribution(Distribution):
diff --git a/version.py b/version.py
index c7868f84..fe4ba514 100644
--- a/version.py
+++ b/version.py
@@ -20,7 +20,7 @@ import subprocess
 
 # ---------------------------------------------------
 
-__version__ = "0.1.dev0"
+__version__ = "0.20.0"
 PROJ_ROOT = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))
 
 
