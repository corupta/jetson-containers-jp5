diff --git a/generate.sh b/generate.sh
index 5e21d508..ea745eed 100755
--- a/generate.sh
+++ b/generate.sh
@@ -12,7 +12,7 @@ cmake ${builder} .. \
     -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \
     -DCMAKE_INSTALL_PREFIX=${WORKSPACE_PATH}/install \
     -DBUILD_PY_FFI=ON \
-    -DBUILD_MULTI_GPU=ON \
+    -DBUILD_MULTI_GPU=OFF \
     -DCMAKE_CUDA_FLAGS="-lineinfo" \
     -DCMAKE_POLICY_VERSION_MINIMUM=3.5 \
     -DUSE_NVTX=ON
diff --git a/lmdeploy/version.py b/lmdeploy/version.py
index 8f34deb9..c59f123d 100644
--- a/lmdeploy/version.py
+++ b/lmdeploy/version.py
@@ -1,7 +1,7 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 from typing import Tuple
 
-__version__ = '0.8.0'
+__version__ = '0.8.1'
 short_version = __version__
 
 
diff --git a/requirements/runtime_cuda.txt b/requirements/runtime_cuda.txt
index 557a8ef2..4b220ead 100644
--- a/requirements/runtime_cuda.txt
+++ b/requirements/runtime_cuda.txt
@@ -7,7 +7,7 @@ numpy<2.0.0
 openai
 outlines
 partial_json_parser
-peft<=0.14.0
+peft<0.16.0
 pillow
 protobuf
 pydantic>2.0.0
@@ -17,8 +17,8 @@ safetensors
 sentencepiece
 shortuuid
 tiktoken
-torch<=2.6.0,>=2.0.0
-torchvision<=0.21.0,>=0.15.0
+torch<=2.7.0,>=2.0.0
+torchvision<=0.22.0,>=0.15.0
 transformers
 triton<=3.2.0,>=3.0.0; sys_platform == "linux"
 uvicorn
diff --git a/src/turbomind/kernels/gemm/convert_v2.cu b/src/turbomind/kernels/gemm/convert_v2.cu
index a718c504..9d99e0b5 100644
--- a/src/turbomind/kernels/gemm/convert_v2.cu
+++ b/src/turbomind/kernels/gemm/convert_v2.cu
@@ -236,10 +236,10 @@ get_weight_and_scales_layout(DataType dtype, bool is_fused_moe, int sm, bool for
             if (sm >= 80) {
                 return {kColMajor, HMMA_16816 | OPERAND_B | 1, {}, {}};
             }
-            else if (sm == 75) {
+            else if (sm >= 75) {
                 return {kColMajor, HMMA_16816 | OPERAND_B | 1, {}, {}};
             }
-            else if (sm == 70) {
+            else if (sm >= 70) {
                 return {kColMajor, HMMA_884 | OPERAND_B | 1, {}, {}};
             }
         }
@@ -247,10 +247,10 @@ get_weight_and_scales_layout(DataType dtype, bool is_fused_moe, int sm, bool for
             if (sm >= 80) {
                 return {kColMajor, HMMA_16816 | OPERAND_B | 2, kRowMajor, HMMA_16816 | OPERAND_V | 1};
             }
-            else if (sm == 75) {
+            else if (sm >= 75) {
                 return {kColMajor, HMMA_16816 | OPERAND_B | 2, kRowMajor, HMMA_16816 | OPERAND_V | 1};
             }
-            else if (sm == 70) {
+            else if (sm >= 70) {
                 return {kColMajor, HMMA_884 | OPERAND_B | 1, kRowMajor, HMMA_884 | OPERAND_V | 1};
             }
         }
@@ -263,10 +263,10 @@ get_weight_and_scales_layout(DataType dtype, bool is_fused_moe, int sm, bool for
             if (sm >= 80) {
                 return {kRowMajor, HMMA_16816 | OPERAND_B | 2, kRowMajor, HMMA_16816 | OPERAND_V | 1};
             }
-            else if (sm == 75) {
+            else if (sm >= 75) {
                 return {kRowMajor, HMMA_16816 | OPERAND_B | 2, kRowMajor, HMMA_16816 | OPERAND_V | 1};
             }
-            else if (sm == 70) {
+            else if (sm >= 70) {
                 return {kColMajor, HMMA_884 | OPERAND_B | 1, kRowMajor, HMMA_884 | OPERAND_V | 1};
             }
         }
